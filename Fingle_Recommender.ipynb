{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f01f6ce",
   "metadata": {},
   "source": [
    "# Fingle Interest-based Recommender (Hybrid)\n",
    "\n",
    "This notebook builds a hybrid recommender combining:\n",
    "- Content signals: overlap between user interests and post tags\n",
    "- Collaborative signals: latent factors from implicit feedback via TruncatedSVD\n",
    "- Popularity prior: global engagement rate per post\n",
    "\n",
    "It evaluates with a user-wise holdout split and reports Precision@3, Recall@3, MAP@3, and NDCG@3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee3a21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  user_id  age gender          top_3_interests  past_engagement_score\n",
       " 0      U1   24      F      sports, art, gaming                   0.61\n",
       " 1      U2   32      F    travel, food, fashion                   0.93\n",
       " 2      U3   28  Other  sports, travel, fashion                   0.40\n",
       " 3      U4   25      M     fashion, music, tech                   0.53\n",
       " 4      U5   24      M   fashion, food, fitness                   0.80,\n",
       "   post_id creator_id content_type            tags\n",
       " 0      P1        U44        video    sports, food\n",
       " 1      P2        U26        video   music, travel\n",
       " 2      P3        U32         text  sports, travel\n",
       " 3      P4         U6        image   music, gaming\n",
       " 4      P5        U32        image   food, fashion,\n",
       "   user_id post_id  engagement\n",
       " 0      U1     P52           1\n",
       " 1      U1     P44           0\n",
       " 2      U1      P1           1\n",
       " 3      U1      P4           1\n",
       " 4      U1     P65           0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import defaultdict\n",
    "\n",
    "USERS_PATH = 'Users.csv'\n",
    "POSTS_PATH = 'Posts.csv'\n",
    "ENG_PATH = 'Engagements.csv'\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "users = pd.read_csv(USERS_PATH)\n",
    "posts = pd.read_csv(POSTS_PATH)\n",
    "eng = pd.read_csv(ENG_PATH)\n",
    "users.head(), posts.head(), eng.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d754a08",
   "metadata": {},
   "source": [
    "## Preprocess columns\n",
    "- Normalize IDs to categorical indices.\n",
    "- Parse user interests and post tags.\n",
    "- Build mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a7ff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean strings and split lists\n",
    "def split_list(s):\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    return [x.strip().lower() for x in str(s).split(',')]\n",
    "\n",
    "users['interests'] = users['top_3_interests'].apply(split_list)\n",
    "posts['tag_list'] = posts['tags'].apply(split_list)\n",
    "\n",
    "# Categorical index mappings\n",
    "user_ids = users['user_id'].astype('category')\n",
    "post_ids = posts['post_id'].astype('category')\n",
    "uid2idx = dict(zip(user_ids, user_ids.cat.codes))\n",
    "pid2idx = dict(zip(post_ids, post_ids.cat.codes))\n",
    "idx2uid = {v:k for k,v in uid2idx.items()}\n",
    "idx2pid = {v:k for k,v in pid2idx.items()}\n",
    "\n",
    "users['uidx'] = users['user_id'].map(uid2idx)\n",
    "posts['pidx'] = posts['post_id'].map(pid2idx)\n",
    "\n",
    "# Join engagement limited to known users/posts\n",
    "eng = eng[eng['user_id'].isin(uid2idx) & eng['post_id'].isin(pid2idx)]\n",
    "eng['uidx'] = eng['user_id'].map(uid2idx)\n",
    "eng['pidx'] = eng['post_id'].map(pid2idx)\n",
    "eng['engagement'] = eng['engagement'].astype(int)\n",
    "\n",
    "n_users = users.shape[0]\n",
    "n_items = posts.shape[0]\n",
    "n_users, n_items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e76eb07",
   "metadata": {},
   "source": [
    "## Train/test split (user-wise holdout)\n",
    "For each user with at least one positive (engagement==1), hold out one positive as test; train on the rest.\n",
    "Negatives remain in train to provide contrastive signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ceab6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, np.int64(53)),\n",
       "  (1, np.int64(16)),\n",
       "  (2, np.int64(28)),\n",
       "  (3, np.int64(60)),\n",
       "  (4, np.int64(60))],\n",
       " (950, 5))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build per-user positives\n",
    "pos_by_user = eng[eng['engagement'] == 1].groupby('uidx')['pidx'].apply(list).to_dict()\n",
    "test_pairs = []\n",
    "train_mask = np.ones(len(eng), dtype=bool)\n",
    "for uidx, plist in pos_by_user.items():\n",
    "    if len(plist) == 0:\n",
    "        continue\n",
    "    # randomly hold out one positive for test\n",
    "    held = np.random.choice(plist)\n",
    "    # mark as test: find first matching row index\n",
    "    test_idx = eng[(eng['uidx']==uidx) & (eng['pidx']==held) & (eng['engagement']==1)].index[0]\n",
    "    train_mask[test_idx] = False\n",
    "    test_pairs.append((uidx, held))\n",
    "\n",
    "train_eng = eng[train_mask].copy()\n",
    "test_pairs[:5], train_eng.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c183683",
   "metadata": {},
   "source": [
    "## Build implicit user-item matrix and train SVD\n",
    "We weight positives as 1.0 and negatives as 0.1 to reduce their influence but keep contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48c7f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 20), (100, 20))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build CSR-like arrays (dense for simplicity; dataset is small)\n",
    "implicit_mat = np.zeros((n_users, n_items), dtype=np.float32)\n",
    "for _, r in train_eng.iterrows():\n",
    "    w = 1.0 if r['engagement'] == 1 else 0.1\n",
    "    implicit_mat[int(r['uidx']), int(r['pidx'])] = max(implicit_mat[int(r['uidx']), int(r['pidx'])], w)\n",
    "\n",
    "# TruncatedSVD for latent factors\n",
    "k = 20 if min(n_users, n_items) > 20 else max(2, min(10, min(n_users, n_items)-1))\n",
    "svd = TruncatedSVD(n_components=k, random_state=RANDOM_SEED)\n",
    "U = svd.fit_transform(implicit_mat)  # user factors in item-space\n",
    "V = svd.components_.T               # item factors\n",
    "U = normalize(U)\n",
    "V = normalize(V)\n",
    "U.shape, V.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19796da5",
   "metadata": {},
   "source": [
    "## Content features and popularity prior\n",
    "- Content: Jaccard similarity between user interests and post tags.\n",
    "- Popularity: global positive rate per post (Laplace-smoothed).\n",
    "- User bias: scale by user `past_engagement_score` as a mild multiplier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058bbced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.61, 0.94, 0.85, 0.71, 0.9 ], dtype=float32),\n",
       " array([0.75      , 0.2       , 0.25      , 0.46153846, 0.6666667 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Content similarity\n",
    "interest_sets = users.set_index('uidx')['interests'].to_dict()\n",
    "tag_sets = posts.set_index('pidx')['tag_list'].to_dict()\n",
    "\n",
    "def jaccard(a, b):\n",
    "    sa, sb = set(a), set(b)\n",
    "    if not sa and not sb:\n",
    "        return 0.0\n",
    "    return len(sa & sb) / (len(sa | sb) + 1e-9)\n",
    "\n",
    "content_mat = np.zeros((n_users, n_items), dtype=np.float32)\n",
    "for u in range(n_users):\n",
    "    ua = interest_sets.get(u, [])\n",
    "    for p in range(n_items):\n",
    "        content_mat[u, p] = jaccard(ua, tag_sets.get(p, []))\n",
    "\n",
    "# Popularity prior (Laplace smoothing)\n",
    "post_pos = train_eng.groupby('pidx')['engagement'].sum()\n",
    "post_cnt = train_eng.groupby('pidx')['engagement'].count()\n",
    "alpha = 1.0\n",
    "pop = (post_pos + alpha) / (post_cnt + 2*alpha)\n",
    "popularity = np.zeros(n_items, dtype=np.float32)\n",
    "for pidx, val in pop.items():\n",
    "    popularity[int(pidx)] = float(val)\n",
    "\n",
    "user_bias = users.set_index('uidx')['past_engagement_score'].fillna(0.5).clip(0,1).astype(float)\n",
    "user_bias = user_bias.reindex(range(n_users), fill_value=0.5).to_numpy().astype(np.float32)\n",
    "user_bias[:5], popularity[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f104a0b7",
   "metadata": {},
   "source": [
    "## Hybrid scoring and recommendation\n",
    "Final score per user–post: \n",
    "`score = w_cf * (U·V) + w_content * content + w_pop * popularity`.\n",
    "Scaled by `(0.75 + 0.5 * user_bias)` to reflect propensity to engage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f330608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['P83', 'P65', 'P25'], ['P29', 'P90', 'P14'], ['P43', 'P33', 'P79']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "w_cf = 0.6\n",
    "w_content = 0.3\n",
    "w_pop = 0.1\n",
    "\n",
    "cf_scores = (U @ V.T)\n",
    "scores = w_cf * cf_scores + w_content * content_mat + w_pop * popularity\n",
    "scales = 0.75 + 0.5 * user_bias.reshape(-1,1)\n",
    "scores = scores * scales\n",
    "\n",
    "# Do not recommend items a user already engaged positively with in train\n",
    "train_pos = train_eng[train_eng['engagement']==1].groupby('uidx')['pidx'].apply(set).to_dict()\n",
    "def recommend_top_k(u, k=3):\n",
    "    s = scores[u].copy()\n",
    "    for p in train_pos.get(u, set()):\n",
    "        s[int(p)] = -1e9\n",
    "    top = np.argpartition(-s, range(min(k, len(s))))[:k]\n",
    "    top = top[np.argsort(-s[top])]\n",
    "    return top\n",
    "\n",
    "# Example: recommendations for first 3 users\n",
    "[ [idx2pid[int(p)] for p in recommend_top_k(u, 3)] for u in range(min(3, n_users)) ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08398c39",
   "metadata": {},
   "source": [
    "## Evaluation (P@3, R@3, MAP@3, NDCG@3)\n",
    "We evaluate against the held-out positive item per user (where available).\n",
    "For users without a held-out positive, they are skipped in metric aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b9c7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users_evaluated': 50,\n",
       " 'Precision@3': 0.006666666666666666,\n",
       " 'Recall@3': 0.02,\n",
       " 'MAP@3': 0.006666666666666666,\n",
       " 'NDCG@3': 0.01}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_at_k(recs, ground_truth, k=3):\n",
    "    if k == 0: return 0.0\n",
    "    hits = sum(1 for p in recs[:k] if p in ground_truth)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recs, ground_truth, k=3):\n",
    "    if len(ground_truth) == 0: return 0.0\n",
    "    hits = sum(1 for p in recs[:k] if p in ground_truth)\n",
    "    return hits / len(ground_truth)\n",
    "\n",
    "def ap_at_k(recs, ground_truth, k=3):\n",
    "    hits = 0\n",
    "    ap = 0.0\n",
    "    for i, p in enumerate(recs[:k], start=1):\n",
    "        if p in ground_truth:\n",
    "            hits += 1\n",
    "            ap += hits / i\n",
    "    return ap / min(len(ground_truth), k) if ground_truth else 0.0\n",
    "\n",
    "def ndcg_at_k(recs, ground_truth, k=3):\n",
    "    def dcg(xs):\n",
    "        return sum(rel/np.log2(i+2) for i, rel in enumerate(xs))\n",
    "    rel = [1.0 if p in ground_truth else 0.0 for p in recs[:k]]\n",
    "    ideal = sorted(rel, reverse=True)\n",
    "    idcg = dcg(ideal)\n",
    "    return dcg(rel) / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# Evaluate\n",
    "p_list, r_list, map_list, ndcg_list = [], [], [], []\n",
    "for u, held in test_pairs:\n",
    "    recs = recommend_top_k(u, k=3)\n",
    "    gt = {held}\n",
    "    p_list.append(precision_at_k(recs, gt, 3))\n",
    "    r_list.append(recall_at_k(recs, gt, 3))\n",
    "    map_list.append(ap_at_k(recs, gt, 3))\n",
    "    ndcg_list.append(ndcg_at_k(recs, gt, 3))\n",
    "\n",
    "metrics = {\n",
    "    'users_evaluated': len(p_list),\n",
    "    'Precision@3': float(np.mean(p_list)) if p_list else None,\n",
    "    'Recall@3': float(np.mean(r_list)) if r_list else None,\n",
    "    'MAP@3': float(np.mean(map_list)) if map_list else None,\n",
    "    'NDCG@3': float(np.mean(ndcg_list)) if ndcg_list else None,\n",
    "}\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40606c6",
   "metadata": {},
   "source": [
    "## Generate Top-3 recommendations per user and save\n",
    "Writes `recommendations_top3.csv` with columns: `user_id,post_id,rank,score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e09027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U1</td>\n",
       "      <td>P83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.403907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U1</td>\n",
       "      <td>P65</td>\n",
       "      <td>2</td>\n",
       "      <td>0.393694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U1</td>\n",
       "      <td>P25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.346324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U10</td>\n",
       "      <td>P29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U10</td>\n",
       "      <td>P90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.421442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id post_id  rank     score\n",
       "0      U1     P83     1  0.403907\n",
       "1      U1     P65     2  0.393694\n",
       "2      U1     P25     3  0.346324\n",
       "3     U10     P29     1  0.453882\n",
       "4     U10     P90     2  0.421442"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for u in range(n_users):\n",
    "    recs = recommend_top_k(u, k=3)\n",
    "    for rank, p in enumerate(recs, start=1):\n",
    "        rows.append({\n",
    "            'user_id': idx2uid[u],\n",
    "            'post_id': idx2pid[int(p)],\n",
    "            'rank': rank,\n",
    "            'score': float(scores[u, int(p)])\n",
    "        })\n",
    "rec_df = pd.DataFrame(rows)\n",
    "rec_df.to_csv('recommendations_top3.csv', index=False)\n",
    "rec_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
